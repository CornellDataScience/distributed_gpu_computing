{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants describing where our training & validation data is located in S3\n",
    "# S3 bucket containing our training & validation datasets\n",
    "BUCKET_NAME = \"databricks-public-datasets\"\n",
    "# AWS region of our S3 bucket\n",
    "S3_REGION = \"us-west-2\"\n",
    "# Prefix of training data filenames within our S3 bucket\n",
    "TRAIN_PREFIX = \"mnist/train\"\n",
    "# Prefix of validation data filenames within our S3 bucket\n",
    "EVAL_PREFIX = \"mnist/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of examples in our validation set, used to ensure we process the entire validation set during each model evaluation step\n",
    "NUM_VALIDATION_EXAMPLES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This directory persistently stores model checkpoints in Databricks' distributed filesystem (DBFS).\n",
    "# Model checkpoints will be preserved across cluster restarts and after training finishes.\n",
    "# If modifying this directory, note that our model training logic assumes that this directory is on\n",
    "# DBFS (begins with \"/dbfs/\").\n",
    "# \n",
    "# Since the checkpoint directory is distributed, its contents can be overwritten by other users or during successive\n",
    "# model training runs; we recommend modifying the code below to use a unique distributed directory for each model\n",
    "# training run (i.e., generate a unique directory name during each run)\n",
    "#\n",
    "# See https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html for more info on DBFS.\n",
    "CHECKPOINT_DIR = \"/dbfs/tmp/mnist-checkpoint-dir\"\n",
    "# This directory persistently stores event files describing model performance on the training & validation datasets.\n",
    "# Event files will be preserved across cluster restarts and after training finishes, and can be consumed by\n",
    "# TensorBoard.\n",
    "DBFS_EVENT_FILE_DIR = \"/dbfs/tmp/mnist-event-file-dir\"\n",
    "# If set to true, the content of the above directories will be destroyed before a run.\n",
    "REMOVE_OLD_DIRS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert CHECKPOINT_DIR.startswith(\"/dbfs\"), \"Checkpoint directory must be on DBFS (start with '/dbfs/'), got non-DBFS checkpoint directory %s\"%CHECKPOINT_DIR\n",
    "assert DBFS_EVENT_FILE_DIR.startswith(\"/dbfs\"), \"Event file directory must be on DBFS (start with '/dbfs/'), got non-DBFS event file directory %s\"%DBFS_EVENT_FILE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Local directory in which to store training data (on the Spark workers) & validation data (on the driver)\n",
    "LOCAL_DATA_DIR = \"/tmp/mnist\"\n",
    "# Local directory in which to store training event files (on the chief Spark worker) & validation event files (on the driver)\n",
    "LOCAL_EVENT_FILE_DIR = \"/tmp/mnist-event-files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-822e54e0a8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Number of Spark executors in the cluster; this field likely does not need to be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNUM_EXECUTORS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultParallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Number of parameter servers; we'll launch NUM_EXECUTORS - NUM_PS Tensorflow workers for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# NUM_PS must be at least 1 and less than NUM_EXECUTORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mNUM_PS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of Spark executors in the cluster; this field likely does not need to be modified\n",
    "NUM_EXECUTORS = sc.defaultParallelism\n",
    "# Number of parameter servers; we'll launch NUM_EXECUTORS - NUM_PS Tensorflow workers for training\n",
    "# NUM_PS must be at least 1 and less than NUM_EXECUTORS\n",
    "NUM_PS = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NUM_PS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3add41d88bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mNUM_PS\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Must use at least one parameter server for model training, got NUM_PS = %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mNUM_PS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mNUM_PS\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mNUM_EXECUTORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Number of parameter servers (%s) must be less than the number of Spark executors (%s)\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_PS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EXECUTORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NUM_PS' is not defined"
     ]
    }
   ],
   "source": [
    "assert NUM_PS > 0, \"Must use at least one parameter server for model training, got NUM_PS = %s\"%NUM_PS\n",
    "assert NUM_PS < NUM_EXECUTORS, \"Number of parameter servers (%s) must be less than the number of Spark executors (%s)\"%(NUM_PS, NUM_EXECUTORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "# Learning rate\n",
    "LEARNING_RATE = 5e-6\n",
    "# Number of (global) training steps to perform\n",
    "TRAIN_STEPS = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
