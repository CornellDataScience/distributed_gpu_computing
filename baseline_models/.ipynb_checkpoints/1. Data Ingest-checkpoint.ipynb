{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/serverteam_1/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%run ./S3DataUtils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-004550c48968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'download_files' is not defined"
     ]
    }
   ],
   "source": [
    "help(download_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse_example(serialized_example):\n",
    "  \"\"\"\n",
    "  Tensorflow example code taken from \n",
    "  https://github.com/tensorflow/tensorflow/blob/v1.4.0/tensorflow/examples/how_tos/reading_data/fully_connected_reader.py#L48.\n",
    "\n",
    "  Parses serialized TFRecord containing a single data point, returning a tuple of tensors (image, label).\n",
    "  \"\"\"\n",
    "  features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "          'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "          'label': tf.FixedLenFeature([], tf.int64),\n",
    "      }\n",
    "  )\n",
    "  IMAGE_PIXELS = 784\n",
    "  # Convert from a scalar string tensor (whose single string has length IMAGE_PIXELS) to a uint8 tensor with shape\n",
    "  # [IMAGE_PIXELS].\n",
    "  image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "  image.set_shape([IMAGE_PIXELS])\n",
    "  # Convert from [0, 255] -> [-0.5, 0.5] floats.\n",
    "  image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n",
    "  # Convert label from a scalar uint8 tensor to a int32 scalar.\n",
    "  label = tf.cast(features['label'], tf.int32)\n",
    "  return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_batch(data_dir, batch_size, num_readers, num_preprocess_threads, file_prefix):\n",
    "  \"\"\" \n",
    "  Returns a tuple of tensors (images, labels) corresponding to a batch of data.\n",
    "  Only reads data from files in data_dir whose names have the specified prefix.\n",
    "  \n",
    "  data_dir: String, local directory containing data files in TFRecord format\n",
    "  batch_size: Int, size of a data batch\n",
    "  num_readers: Int, number of threads concurrently reading from data files\n",
    "  num_preprocess_threads: Int, number of threads concurrently parsing serialized examples into (image, label) Tensor pairs\n",
    "  file_prefix: String, prefix (e.g. \"train\" or \"validation\") of files in data_dir from which to read examples\n",
    "  \"\"\"\n",
    "\n",
    "  # Adapted from https://www.tensorflow.org/versions/r1.4/api_docs/python/tf/contrib/data/Dataset\n",
    "  tf_record_pattern = os.path.join(data_dir, \"%s*\"%file_prefix)\n",
    "  tf.logging.info(\"Reading training data from files matching glob pattern %s\"%tf_record_pattern)\n",
    "  # Create base dataset of all files matching the glob pattern above\n",
    "  d = tf.data.Dataset.list_files(tf_record_pattern)\n",
    "  # Apply transformations to obtain a Dataset consisting of a repeated, shuffled sequence of files\n",
    "  d = d.repeat()\n",
    "  d = d.shuffle(buffer_size=32)\n",
    "  d = d.repeat()\n",
    "  # Get a Dataset of shuffled TFRecord objects (each TFRecord = a serialized training point) \n",
    "  # read in parallel from our data files\n",
    "  d = d.interleave(tf.data.TFRecordDataset,\n",
    "                   cycle_length=num_readers, block_length=1)\n",
    "  # Apply the _parse_example function to each TFRecord to obtain a tuple of Tensors (image, label)\n",
    "  d = d.map(_parse_example, num_parallel_calls=num_preprocess_threads)\n",
    "  # Get an iterator over a dataset of batched training examples, return tuple (images, labels) from iterator\n",
    "  d = d.batch(batch_size)\n",
    "  return d.make_one_shot_iterator().get_next()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
